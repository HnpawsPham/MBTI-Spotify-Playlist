{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "82ccbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9c1a64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbti</th>\n",
       "      <th>function_pair</th>\n",
       "      <th>danceability_mean</th>\n",
       "      <th>danceability_stdev</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_stdev</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_stdev</th>\n",
       "      <th>mode_mean</th>\n",
       "      <th>mode_stdev</th>\n",
       "      <th>speechiness_mean</th>\n",
       "      <th>speechiness_stdev</th>\n",
       "      <th>acousticness_mean</th>\n",
       "      <th>acousticness_stdev</th>\n",
       "      <th>liveness_mean</th>\n",
       "      <th>liveness_stdev</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>valence_stdev</th>\n",
       "      <th>tempo_mean</th>\n",
       "      <th>tempo_stdev</th>\n",
       "      <th>instrumentalness_mean</th>\n",
       "      <th>instrumentalness_stdev</th>\n",
       "      <th>Cminor_count</th>\n",
       "      <th>CMajor_count</th>\n",
       "      <th>C#/Dbminor_count</th>\n",
       "      <th>C#/DbMajor_count</th>\n",
       "      <th>DMajor_count</th>\n",
       "      <th>D#_EbMajor_count</th>\n",
       "      <th>Eminor_count</th>\n",
       "      <th>EMajor_count</th>\n",
       "      <th>Fminor_count</th>\n",
       "      <th>FMajor_count</th>\n",
       "      <th>F#/Gbminor_count</th>\n",
       "      <th>GMajor_count</th>\n",
       "      <th>G#/Abminor_count</th>\n",
       "      <th>G#/AbMajor_count</th>\n",
       "      <th>Aminor_count</th>\n",
       "      <th>AMajor_count</th>\n",
       "      <th>A#/Bbminor_count</th>\n",
       "      <th>BMajor_count</th>\n",
       "      <th>Dminor_count</th>\n",
       "      <th>D#_Ebminor_count</th>\n",
       "      <th>Gminor_count</th>\n",
       "      <th>A#/BbMajor_count</th>\n",
       "      <th>F#/GbMajor_count</th>\n",
       "      <th>Bminor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>SJ</td>\n",
       "      <td>0.552889</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.595611</td>\n",
       "      <td>0.137195</td>\n",
       "      <td>-7.224889</td>\n",
       "      <td>2.101033</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.514496</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.299630</td>\n",
       "      <td>0.301594</td>\n",
       "      <td>0.130150</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.364722</td>\n",
       "      <td>0.184167</td>\n",
       "      <td>129.453222</td>\n",
       "      <td>34.684798</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>0.136504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>SJ</td>\n",
       "      <td>0.517780</td>\n",
       "      <td>0.142557</td>\n",
       "      <td>0.674940</td>\n",
       "      <td>0.182267</td>\n",
       "      <td>-7.902200</td>\n",
       "      <td>2.822676</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.494872</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.043208</td>\n",
       "      <td>0.146922</td>\n",
       "      <td>0.211668</td>\n",
       "      <td>0.212286</td>\n",
       "      <td>0.162003</td>\n",
       "      <td>0.360696</td>\n",
       "      <td>0.234499</td>\n",
       "      <td>114.934620</td>\n",
       "      <td>24.479429</td>\n",
       "      <td>0.197203</td>\n",
       "      <td>0.308495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>SJ</td>\n",
       "      <td>0.585313</td>\n",
       "      <td>0.181908</td>\n",
       "      <td>0.694375</td>\n",
       "      <td>0.173636</td>\n",
       "      <td>-5.307063</td>\n",
       "      <td>1.531874</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.512348</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.086054</td>\n",
       "      <td>0.153912</td>\n",
       "      <td>0.244173</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.106532</td>\n",
       "      <td>0.522062</td>\n",
       "      <td>0.243778</td>\n",
       "      <td>122.609875</td>\n",
       "      <td>33.198061</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>SJ</td>\n",
       "      <td>0.636040</td>\n",
       "      <td>0.152382</td>\n",
       "      <td>0.652420</td>\n",
       "      <td>0.176042</td>\n",
       "      <td>-6.553020</td>\n",
       "      <td>2.813042</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>0.209508</td>\n",
       "      <td>0.222048</td>\n",
       "      <td>0.156414</td>\n",
       "      <td>0.123012</td>\n",
       "      <td>0.558718</td>\n",
       "      <td>0.277860</td>\n",
       "      <td>125.042880</td>\n",
       "      <td>29.284283</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>SJ</td>\n",
       "      <td>0.640733</td>\n",
       "      <td>0.145205</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.182482</td>\n",
       "      <td>-5.763733</td>\n",
       "      <td>2.075266</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.502519</td>\n",
       "      <td>0.106978</td>\n",
       "      <td>0.077171</td>\n",
       "      <td>0.148807</td>\n",
       "      <td>0.165350</td>\n",
       "      <td>0.192504</td>\n",
       "      <td>0.126879</td>\n",
       "      <td>0.555711</td>\n",
       "      <td>0.231692</td>\n",
       "      <td>123.650378</td>\n",
       "      <td>27.039630</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mbti function_pair  ...  F#/GbMajor_count  Bminor_count\n",
       "4076  ESTJ            SJ  ...               0.0           2.0\n",
       "4077  ESTJ            SJ  ...               1.0           4.0\n",
       "4078  ESTJ            SJ  ...               0.0           1.0\n",
       "4079  ESTJ            SJ  ...               1.0           3.0\n",
       "4080  ESTJ            SJ  ...               2.0           2.0\n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./csv/combined_mbti_df.csv\")\n",
    "\n",
    "df = df.drop_duplicates().dropna()\n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b22f9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_features = [\n",
    "    \"danceability_mean\", \"danceability_stdev\",\n",
    "    \"energy_mean\", \"energy_stdev\",\n",
    "    \"loudness_mean\", \"loudness_stdev\",\n",
    "    \"mode_mean\", \"mode_stdev\",\n",
    "    \"speechiness_mean\", \"speechiness_stdev\",\n",
    "    \"acousticness_mean\", \"acousticness_stdev\",\n",
    "    \"liveness_mean\", \"liveness_stdev\",\n",
    "    \"valence_mean\", \"valence_stdev\",\n",
    "    \"tempo_mean\", \"tempo_stdev\",\n",
    "    \"instrumentalness_mean\", \"instrumentalness_stdev\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d6d02",
   "metadata": {},
   "source": [
    "### CONVERT TO 4 LETTER COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1aa1b62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbti</th>\n",
       "      <th>function_pair</th>\n",
       "      <th>danceability_mean</th>\n",
       "      <th>danceability_stdev</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_stdev</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_stdev</th>\n",
       "      <th>mode_mean</th>\n",
       "      <th>mode_stdev</th>\n",
       "      <th>speechiness_mean</th>\n",
       "      <th>speechiness_stdev</th>\n",
       "      <th>acousticness_mean</th>\n",
       "      <th>acousticness_stdev</th>\n",
       "      <th>liveness_mean</th>\n",
       "      <th>liveness_stdev</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>valence_stdev</th>\n",
       "      <th>tempo_mean</th>\n",
       "      <th>tempo_stdev</th>\n",
       "      <th>instrumentalness_mean</th>\n",
       "      <th>instrumentalness_stdev</th>\n",
       "      <th>Cminor_count</th>\n",
       "      <th>CMajor_count</th>\n",
       "      <th>C#/Dbminor_count</th>\n",
       "      <th>C#/DbMajor_count</th>\n",
       "      <th>DMajor_count</th>\n",
       "      <th>D#_EbMajor_count</th>\n",
       "      <th>Eminor_count</th>\n",
       "      <th>EMajor_count</th>\n",
       "      <th>Fminor_count</th>\n",
       "      <th>FMajor_count</th>\n",
       "      <th>F#/Gbminor_count</th>\n",
       "      <th>GMajor_count</th>\n",
       "      <th>G#/Abminor_count</th>\n",
       "      <th>G#/AbMajor_count</th>\n",
       "      <th>Aminor_count</th>\n",
       "      <th>AMajor_count</th>\n",
       "      <th>A#/Bbminor_count</th>\n",
       "      <th>BMajor_count</th>\n",
       "      <th>Dminor_count</th>\n",
       "      <th>D#_Ebminor_count</th>\n",
       "      <th>Gminor_count</th>\n",
       "      <th>A#/BbMajor_count</th>\n",
       "      <th>F#/GbMajor_count</th>\n",
       "      <th>Bminor_count</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>0.557841</td>\n",
       "      <td>0.155011</td>\n",
       "      <td>0.553325</td>\n",
       "      <td>0.225178</td>\n",
       "      <td>-8.352591</td>\n",
       "      <td>3.273317</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.479495</td>\n",
       "      <td>0.067341</td>\n",
       "      <td>0.061083</td>\n",
       "      <td>0.293469</td>\n",
       "      <td>0.286088</td>\n",
       "      <td>0.163402</td>\n",
       "      <td>0.086266</td>\n",
       "      <td>0.448884</td>\n",
       "      <td>0.221764</td>\n",
       "      <td>120.954795</td>\n",
       "      <td>32.165778</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.081805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>0.587636</td>\n",
       "      <td>0.135644</td>\n",
       "      <td>0.556273</td>\n",
       "      <td>0.191642</td>\n",
       "      <td>-8.215697</td>\n",
       "      <td>3.356867</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.488504</td>\n",
       "      <td>0.074273</td>\n",
       "      <td>0.083388</td>\n",
       "      <td>0.341434</td>\n",
       "      <td>0.267077</td>\n",
       "      <td>0.154542</td>\n",
       "      <td>0.112496</td>\n",
       "      <td>0.447603</td>\n",
       "      <td>0.216069</td>\n",
       "      <td>131.871242</td>\n",
       "      <td>33.216008</td>\n",
       "      <td>0.061041</td>\n",
       "      <td>0.177559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.128009</td>\n",
       "      <td>0.851280</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>-5.046100</td>\n",
       "      <td>2.180554</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.498569</td>\n",
       "      <td>0.272546</td>\n",
       "      <td>0.176013</td>\n",
       "      <td>0.058085</td>\n",
       "      <td>0.074818</td>\n",
       "      <td>0.264520</td>\n",
       "      <td>0.208097</td>\n",
       "      <td>0.265030</td>\n",
       "      <td>0.170518</td>\n",
       "      <td>128.206020</td>\n",
       "      <td>26.927194</td>\n",
       "      <td>0.250358</td>\n",
       "      <td>0.331805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.169477</td>\n",
       "      <td>0.513412</td>\n",
       "      <td>0.258345</td>\n",
       "      <td>-10.172833</td>\n",
       "      <td>4.935140</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.051510</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.442163</td>\n",
       "      <td>0.367025</td>\n",
       "      <td>0.152645</td>\n",
       "      <td>0.095956</td>\n",
       "      <td>0.337845</td>\n",
       "      <td>0.211890</td>\n",
       "      <td>120.593571</td>\n",
       "      <td>34.335224</td>\n",
       "      <td>0.210927</td>\n",
       "      <td>0.294346</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NF</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.141450</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.242592</td>\n",
       "      <td>-10.572240</td>\n",
       "      <td>5.685179</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.388088</td>\n",
       "      <td>0.065178</td>\n",
       "      <td>0.058684</td>\n",
       "      <td>0.479677</td>\n",
       "      <td>0.361406</td>\n",
       "      <td>0.169092</td>\n",
       "      <td>0.126635</td>\n",
       "      <td>0.351366</td>\n",
       "      <td>0.195116</td>\n",
       "      <td>114.693080</td>\n",
       "      <td>30.034142</td>\n",
       "      <td>0.069537</td>\n",
       "      <td>0.206277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mbti function_pair  danceability_mean  danceability_stdev  ...  IE  NS  TF  JP\n",
       "0  INFP            NF           0.557841            0.155011  ...   0   0   1   1\n",
       "1  INFP            NF           0.587636            0.135644  ...   0   0   1   1\n",
       "2  INFP            NF           0.677000            0.128009  ...   0   0   1   1\n",
       "3  INFP            NF           0.517000            0.169477  ...   0   0   1   1\n",
       "4  INFP            NF           0.560400            0.141450  ...   0   0   1   1\n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"IE\"] = df[\"mbti\"].str[0].map({'I': 0, 'E': 1})\n",
    "df[\"NS\"] = df[\"mbti\"].str[1].map({'N': 0, 'S': 1})\n",
    "df[\"TF\"] = df[\"mbti\"].str[2].map({'T': 0, 'F': 1})\n",
    "df[\"JP\"] = df[\"mbti\"].str[3].map({'J': 0, 'P': 1})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3dfe17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[playlist_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4188a",
   "metadata": {},
   "source": [
    "### TRAIN MODEL (BY EACH LETTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        shuffle=True)\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    model = Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(x.shape[1],)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              epochs=30, \n",
    "              validation_split=0.1,\n",
    "              class_weight=class_weights)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return model, accuracy, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f7acfd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6147 - loss: 0.6587 - val_accuracy: 0.7094 - val_loss: 0.6275\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.6092 - val_accuracy: 0.7094 - val_loss: 0.6080\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.5768 - val_accuracy: 0.7250 - val_loss: 0.6034\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5911 - val_accuracy: 0.7125 - val_loss: 0.6040\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7123 - loss: 0.5636 - val_accuracy: 0.7156 - val_loss: 0.6017\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7205 - loss: 0.5654 - val_accuracy: 0.7094 - val_loss: 0.5970\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.5554 - val_accuracy: 0.7250 - val_loss: 0.5930\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5602 - val_accuracy: 0.7156 - val_loss: 0.5901\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7222 - loss: 0.5577 - val_accuracy: 0.7219 - val_loss: 0.5936\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5577 - val_accuracy: 0.7156 - val_loss: 0.5931\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.5482 - val_accuracy: 0.6969 - val_loss: 0.5973\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.5476 - val_accuracy: 0.7031 - val_loss: 0.5941\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 0.5514 - val_accuracy: 0.7031 - val_loss: 0.5956\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5371 - val_accuracy: 0.7125 - val_loss: 0.5948\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5380 - val_accuracy: 0.6969 - val_loss: 0.5927\n",
      "Epoch 16/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7156 - loss: 0.5456 - val_accuracy: 0.7031 - val_loss: 0.5957\n",
      "Epoch 17/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.5188 - val_accuracy: 0.6906 - val_loss: 0.6020\n",
      "Epoch 18/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7528 - loss: 0.5233 - val_accuracy: 0.6938 - val_loss: 0.5980\n",
      "Epoch 19/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7473 - loss: 0.5284 - val_accuracy: 0.7063 - val_loss: 0.5957\n",
      "Epoch 20/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7539 - loss: 0.5199 - val_accuracy: 0.7031 - val_loss: 0.6003\n",
      "Epoch 21/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.5310 - val_accuracy: 0.7063 - val_loss: 0.5968\n",
      "Epoch 22/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.5306 - val_accuracy: 0.7000 - val_loss: 0.6024\n",
      "Epoch 23/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5251 - val_accuracy: 0.7000 - val_loss: 0.5997\n",
      "Epoch 24/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.5146 - val_accuracy: 0.6844 - val_loss: 0.5980\n",
      "Epoch 25/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.5196 - val_accuracy: 0.7031 - val_loss: 0.5949\n",
      "Epoch 26/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5141 - val_accuracy: 0.6906 - val_loss: 0.5982\n",
      "Epoch 27/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.5313 - val_accuracy: 0.7063 - val_loss: 0.6006\n",
      "Epoch 28/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.5105 - val_accuracy: 0.6969 - val_loss: 0.5980\n",
      "Epoch 29/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.4978 - val_accuracy: 0.6938 - val_loss: 0.5980\n",
      "Epoch 30/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.5029 - val_accuracy: 0.6969 - val_loss: 0.6067\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4724 - loss: 0.7941 - val_accuracy: 0.5250 - val_loss: 0.6938\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5611 - loss: 0.6920 - val_accuracy: 0.5500 - val_loss: 0.6735\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5732 - loss: 0.6774 - val_accuracy: 0.5813 - val_loss: 0.6720\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5607 - loss: 0.6772 - val_accuracy: 0.5906 - val_loss: 0.6585\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.6706 - val_accuracy: 0.5781 - val_loss: 0.6646\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.6711 - val_accuracy: 0.5844 - val_loss: 0.6610\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.6599 - val_accuracy: 0.5906 - val_loss: 0.6606\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6272 - loss: 0.6521 - val_accuracy: 0.5938 - val_loss: 0.6617\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.6562 - val_accuracy: 0.5938 - val_loss: 0.6594\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 0.6603 - val_accuracy: 0.6031 - val_loss: 0.6579\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.6545 - val_accuracy: 0.6250 - val_loss: 0.6484\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6140 - loss: 0.6557 - val_accuracy: 0.6000 - val_loss: 0.6502\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6261 - loss: 0.6445 - val_accuracy: 0.5969 - val_loss: 0.6496\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: 0.6410 - val_accuracy: 0.6031 - val_loss: 0.6536\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6235 - loss: 0.6460 - val_accuracy: 0.5938 - val_loss: 0.6566\n",
      "Epoch 16/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6263 - loss: 0.6442 - val_accuracy: 0.5938 - val_loss: 0.6519\n",
      "Epoch 17/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6291 - loss: 0.6413 - val_accuracy: 0.6000 - val_loss: 0.6517\n",
      "Epoch 18/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6312 - loss: 0.6415 - val_accuracy: 0.5844 - val_loss: 0.6487\n",
      "Epoch 19/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6648 - loss: 0.6230 - val_accuracy: 0.5938 - val_loss: 0.6499\n",
      "Epoch 20/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 0.6293 - val_accuracy: 0.5906 - val_loss: 0.6577\n",
      "Epoch 21/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.6415 - val_accuracy: 0.6000 - val_loss: 0.6523\n",
      "Epoch 22/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6535 - loss: 0.6355 - val_accuracy: 0.5875 - val_loss: 0.6469\n",
      "Epoch 23/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6412 - loss: 0.6350 - val_accuracy: 0.6156 - val_loss: 0.6462\n",
      "Epoch 24/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 0.6375 - val_accuracy: 0.6125 - val_loss: 0.6500\n",
      "Epoch 25/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 0.6151 - val_accuracy: 0.6062 - val_loss: 0.6569\n",
      "Epoch 26/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.6305 - val_accuracy: 0.5969 - val_loss: 0.6485\n",
      "Epoch 27/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6463 - loss: 0.6281 - val_accuracy: 0.5938 - val_loss: 0.6491\n",
      "Epoch 28/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6493 - loss: 0.6257 - val_accuracy: 0.6094 - val_loss: 0.6456\n",
      "Epoch 29/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6478 - loss: 0.6351 - val_accuracy: 0.6125 - val_loss: 0.6478\n",
      "Epoch 30/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6558 - loss: 0.6187 - val_accuracy: 0.6219 - val_loss: 0.6434\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 0.6931 - val_accuracy: 0.7063 - val_loss: 0.6047\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.5810 - val_accuracy: 0.6781 - val_loss: 0.5906\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5751 - val_accuracy: 0.6938 - val_loss: 0.5815\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5691 - val_accuracy: 0.7000 - val_loss: 0.5779\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.5712 - val_accuracy: 0.6781 - val_loss: 0.5802\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.5550 - val_accuracy: 0.7063 - val_loss: 0.5765\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5512 - val_accuracy: 0.7188 - val_loss: 0.5743\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5519 - val_accuracy: 0.7094 - val_loss: 0.5782\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7247 - loss: 0.5682 - val_accuracy: 0.7094 - val_loss: 0.5728\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.5582 - val_accuracy: 0.7031 - val_loss: 0.5747\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5387 - val_accuracy: 0.7000 - val_loss: 0.5709\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.5571 - val_accuracy: 0.6969 - val_loss: 0.5772\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5379 - val_accuracy: 0.7156 - val_loss: 0.5728\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5451 - val_accuracy: 0.7188 - val_loss: 0.5730\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.5312 - val_accuracy: 0.7094 - val_loss: 0.5695\n",
      "Epoch 16/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7475 - loss: 0.5349 - val_accuracy: 0.7219 - val_loss: 0.5724\n",
      "Epoch 17/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5348 - val_accuracy: 0.7031 - val_loss: 0.5718\n",
      "Epoch 18/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7415 - loss: 0.5365 - val_accuracy: 0.7094 - val_loss: 0.5714\n",
      "Epoch 19/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7469 - loss: 0.5226 - val_accuracy: 0.7156 - val_loss: 0.5693\n",
      "Epoch 20/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7442 - loss: 0.5373 - val_accuracy: 0.7188 - val_loss: 0.5710\n",
      "Epoch 21/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7471 - loss: 0.5228 - val_accuracy: 0.7156 - val_loss: 0.5703\n",
      "Epoch 22/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.5181 - val_accuracy: 0.7219 - val_loss: 0.5741\n",
      "Epoch 23/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7515 - loss: 0.5306 - val_accuracy: 0.7188 - val_loss: 0.5728\n",
      "Epoch 24/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.5255 - val_accuracy: 0.7188 - val_loss: 0.5708\n",
      "Epoch 25/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7520 - loss: 0.5234 - val_accuracy: 0.7188 - val_loss: 0.5738\n",
      "Epoch 26/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.5355 - val_accuracy: 0.7125 - val_loss: 0.5717\n",
      "Epoch 27/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5366 - val_accuracy: 0.7312 - val_loss: 0.5703\n",
      "Epoch 28/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5290 - val_accuracy: 0.7250 - val_loss: 0.5696\n",
      "Epoch 29/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.5160 - val_accuracy: 0.7250 - val_loss: 0.5661\n",
      "Epoch 30/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7555 - loss: 0.5251 - val_accuracy: 0.7250 - val_loss: 0.5704\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5201 - loss: 0.7139 - val_accuracy: 0.6531 - val_loss: 0.6323\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5670 - loss: 0.6824 - val_accuracy: 0.6656 - val_loss: 0.6286\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.6600 - val_accuracy: 0.6687 - val_loss: 0.6254\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.6599 - val_accuracy: 0.6531 - val_loss: 0.6221\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.6564 - val_accuracy: 0.6625 - val_loss: 0.6259\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6270 - loss: 0.6449 - val_accuracy: 0.6594 - val_loss: 0.6257\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 0.6503 - val_accuracy: 0.6562 - val_loss: 0.6228\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5969 - loss: 0.6603 - val_accuracy: 0.6625 - val_loss: 0.6182\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.6435 - val_accuracy: 0.6594 - val_loss: 0.6222\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6145 - loss: 0.6468 - val_accuracy: 0.6719 - val_loss: 0.6175\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6337 - loss: 0.6316 - val_accuracy: 0.6594 - val_loss: 0.6190\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.6385 - val_accuracy: 0.6656 - val_loss: 0.6207\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6340 - loss: 0.6339 - val_accuracy: 0.6531 - val_loss: 0.6230\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6351 - loss: 0.6255 - val_accuracy: 0.6469 - val_loss: 0.6234\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6303 - loss: 0.6326 - val_accuracy: 0.6687 - val_loss: 0.6206\n",
      "Epoch 16/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6522 - loss: 0.6188 - val_accuracy: 0.6562 - val_loss: 0.6219\n",
      "Epoch 17/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.6307 - val_accuracy: 0.6500 - val_loss: 0.6216\n",
      "Epoch 18/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6433 - loss: 0.6227 - val_accuracy: 0.6687 - val_loss: 0.6191\n",
      "Epoch 19/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6521 - loss: 0.6306 - val_accuracy: 0.6656 - val_loss: 0.6152\n",
      "Epoch 20/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6479 - loss: 0.6235 - val_accuracy: 0.6500 - val_loss: 0.6213\n",
      "Epoch 21/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6513 - loss: 0.6227 - val_accuracy: 0.6438 - val_loss: 0.6168\n",
      "Epoch 22/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6468 - loss: 0.6204 - val_accuracy: 0.6313 - val_loss: 0.6199\n",
      "Epoch 23/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: 0.6280 - val_accuracy: 0.6687 - val_loss: 0.6177\n",
      "Epoch 24/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6568 - loss: 0.6245 - val_accuracy: 0.6719 - val_loss: 0.6196\n",
      "Epoch 25/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.6078 - val_accuracy: 0.6438 - val_loss: 0.6229\n",
      "Epoch 26/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6725 - loss: 0.5997 - val_accuracy: 0.6531 - val_loss: 0.6218\n",
      "Epoch 27/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6606 - loss: 0.6180 - val_accuracy: 0.6625 - val_loss: 0.6180\n",
      "Epoch 28/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6525 - loss: 0.6109 - val_accuracy: 0.6469 - val_loss: 0.6290\n",
      "Epoch 29/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6541 - loss: 0.6121 - val_accuracy: 0.6531 - val_loss: 0.6187\n",
      "Epoch 30/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6831 - loss: 0.5995 - val_accuracy: 0.6562 - val_loss: 0.6171\n"
     ]
    }
   ],
   "source": [
    "ie_model, ie_accuracy, x_ie_test, y_ie_test = train_model(x, df[\"IE\"])\n",
    "ns_model, ns_accuracy, x_ns_test, y_ns_test = train_model(x, df[\"NS\"])\n",
    "tf_model, tf_accuracy, x_tf_test, y_tf_test = train_model(x, df[\"TF\"])\n",
    "jp_model, jp_accuracy, x_jp_test, y_jp_test = train_model(x, df[\"JP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c56387e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "    \"ie_model\": (ie_model, ie_accuracy),\n",
    "    \"ns_model\": (ns_model, ns_accuracy),\n",
    "    \"tf_model\": (tf_model, tf_accuracy),\n",
    "    \"jp_model\": (jp_model, jp_accuracy),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89288f60",
   "metadata": {},
   "source": [
    "### SAVE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "067c932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359198927879333 0.75844806432724\n",
      "0.5944930911064148 0.6382978723404256\n",
      "0.7334167957305908 0.7484355568885803\n",
      "0.5982478260993958 0.6070087609511889\n"
     ]
    }
   ],
   "source": [
    "# load record\n",
    "with open(\"./models/accuracy_record.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "def new_save(model, accuracy, name):\n",
    "    print(accuracy, config[name])\n",
    "    if accuracy > config[name]:\n",
    "        config[name] = accuracy\n",
    "        model.save(f\"./models/{name}.keras\")  \n",
    "\n",
    "for name, (model, accuracy) in model_info.items():\n",
    "    new_save(model, accuracy, name)\n",
    "\n",
    "# save record\n",
    "with open(\"./models/accuracy_record.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2c2f1",
   "metadata": {},
   "source": [
    "### LOAD MODEL FROM SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "27da84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_save(name):\n",
    "    return load_model(f\"./models/{name}.keras\")\n",
    "\n",
    "# for name, (model, _) in model_info.items():\n",
    "#     model = load_from_save(name)\n",
    "\n",
    "ie_model = load_from_save(\"ie_model\")\n",
    "ns_model = load_from_save(\"ns_model\")\n",
    "tf_model = load_from_save(\"tf_model\")\n",
    "jp_model = load_from_save(\"jp_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6cb5f",
   "metadata": {},
   "source": [
    "### TEST PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b6df8da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Pred: ENTJ       | Actual: ENTJ\n",
      "Pred: ISFJ       | Actual: ENFJ\n",
      "Pred: ENTP       | Actual: ENTP\n",
      "Pred: ISFJ       | Actual: INFJ\n",
      "Pred: ESTP       | Actual: ESTJ\n",
      "Pred: ESTP       | Actual: INTJ\n",
      "Pred: ENTJ       | Actual: INTJ\n",
      "Pred: ENTP       | Actual: ENFP\n",
      "Pred: ISFJ       | Actual: INFP\n",
      "Pred: INFJ       | Actual: ISFP\n",
      "Pred: ESFP       | Actual: ENFJ\n",
      "Pred: ESTP       | Actual: ESTP\n",
      "Pred: ISFP       | Actual: INFJ\n",
      "Pred: INTP       | Actual: INFP\n",
      "Pred: ESFP       | Actual: ISFJ\n",
      "Pred: INTP       | Actual: ISFP\n",
      "Pred: ENTJ       | Actual: INTJ\n",
      "Pred: ESFP       | Actual: ESFP\n",
      "Pred: ESTP       | Actual: ESTP\n",
      "Pred: ESTJ       | Actual: ISTP\n"
     ]
    }
   ],
   "source": [
    "ie_pred = (ie_model.predict(x_ie_test) > 0.5).astype(int).reshape(-1)\n",
    "ns_pred = (ns_model.predict(x_ns_test) > 0.5).astype(int).reshape(-1)\n",
    "tf_pred = (tf_model.predict(x_tf_test) > 0.5).astype(int).reshape(-1)\n",
    "jp_pred = (jp_model.predict(x_jp_test) > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "# Map to MBTI\n",
    "def get_mbti(ie, ns, tf, jp):\n",
    "    return f\"{'E' if ie else 'I'}{'S' if ns else 'N'}{'F' if tf else 'T'}{'P' if jp else 'J'}\"\n",
    "\n",
    "pred_mbti = [get_mbti(ie_pred[i], ns_pred[i], tf_pred[i], jp_pred[i]) for i in range(len(ie_pred))]\n",
    "\n",
    "actual_mbti = [\n",
    "    get_mbti(y_ie_test.iloc[i], y_ns_test.iloc[i], y_tf_test.iloc[i], y_jp_test.iloc[i])\n",
    "    for i in range(len(y_ie_test))\n",
    "]\n",
    "\n",
    "# So sánh\n",
    "for p, a in zip(pred_mbti[:20], actual_mbti[:20]):\n",
    "    print(f\"Pred: {p:<10} | Actual: {a}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b7f13",
   "metadata": {},
   "source": [
    "### MORE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3f8ae82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  ESTJ"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti = \"INFP\"\n",
    "\n",
    "test_df = pd.read_csv(f\"./csv/{mbti}_df.csv\")\n",
    "\n",
    "test_data = test_df[playlist_features]\n",
    "\n",
    "ie_pred = (ie_model.predict(test_data) > 0.5).astype(int).reshape(-1)\n",
    "ns_pred = (ns_model.predict(test_data) > 0.5).astype(int).reshape(-1)\n",
    "tf_pred = (tf_model.predict(test_data) > 0.5).astype(int).reshape(-1)\n",
    "jp_pred = (jp_model.predict(test_data) > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "# Map to MBTI\n",
    "def get_mbti(ie, ns, tf, jp):\n",
    "    return f\"{'E' if ie else 'I'}{'S' if ns else 'N'}{'F' if tf else 'T'}{'P' if jp else 'J'}\"\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in range(len(ie_pred)):\n",
    "    mbti_pred = get_mbti(ie_pred[i], ns_pred[i], tf_pred[i], jp_pred[i])\n",
    "    res.append(mbti_pred)\n",
    "\n",
    "table = pd.DataFrame(res).drop_duplicates()\n",
    "table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
